{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0172e3e",
   "metadata": {},
   "source": [
    "# Treinamento de modelo para dataset Elo7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6719f4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "\n",
    "from multiprocessing import cpu_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f103c0",
   "metadata": {},
   "source": [
    "## 1. Carregamento de dados\n",
    "\n",
    "Carregando apenas as colunas que serão usadas pelo modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edb4722c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38507, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    os.environ[\"DATASET_PATH\"],\n",
    "    usecols=[\"title\", \"concatenated_tags\", \"category\"],\n",
    ")\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2187c12",
   "metadata": {},
   "source": [
    "Removendo as entradas que possuem valores em branco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45164537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38505, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569b9298",
   "metadata": {},
   "source": [
    "### Divisão em conjuntos de teste e de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef349022",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"title\", \"concatenated_tags\"]] \n",
    "y = df[\"category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c41398f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lembrancinhas         17759\n",
       "Decoração              8845\n",
       "Bebê                   7026\n",
       "Papel e Cia            2777\n",
       "Outros                 1147\n",
       "Bijuterias e Jóias      951\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c11476f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=123, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3361fd88",
   "metadata": {},
   "source": [
    "## 2. Transformação dos dados, modelagem e validação do modelo\n",
    "\n",
    "Aqui crio uma pipeline de treinamento que cria um count vectorizer das colunas necessárias e depois utilizamos o Naive Bayes multinomial para classificar os dados.\n",
    "\n",
    "Utilizei a pipeline do scikit-learn com um [helper](https://scikit-learn.org/0.18/auto_examples/hetero_feature_union.html) para selecionar as colunas e realizar os vectorizers de forma individual para cada feature.\n",
    "\n",
    "\n",
    "Além disso, é feito um grid-search com cross-validation (5 folds) para encontrar os parâmetros que fazem com que a performance seja melhor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dfed524",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"For data grouped by feature, select subset of data at a provided key.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    key : hashable, required\n",
    "        The key corresponding to the desired value in a mappable.\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, data_dict):\n",
    "        return data_dict[self.key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f6d6d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "\n",
    "    # Use FeatureUnion to combine the features from title and concatenated tags\n",
    "    ('union', FeatureUnion(\n",
    "        transformer_list=[\n",
    "\n",
    "            # Pulling features from the title\n",
    "            ('title', Pipeline([\n",
    "                ('selector', ColumnSelector(key='title')),\n",
    "                ('countvectorizer', CountVectorizer()),\n",
    "            ])),\n",
    "\n",
    "            # Pulling features from concatenated tags\n",
    "            ('concatenated_tags', Pipeline([\n",
    "                ('selector', ColumnSelector(key='concatenated_tags')),\n",
    "                ('countvectorizer', CountVectorizer()),\n",
    "            ])),\n",
    "        ],\n",
    "\n",
    "    )),\n",
    "\n",
    "    # Use a SVC classifier on the combined features\n",
    "    ('multinomialnb', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fb22462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('union',\n",
       "                                        FeatureUnion(transformer_list=[('title',\n",
       "                                                                        Pipeline(steps=[('selector',\n",
       "                                                                                         ColumnSelector(key='title')),\n",
       "                                                                                        ('countvectorizer',\n",
       "                                                                                         CountVectorizer())])),\n",
       "                                                                       ('concatenated_tags',\n",
       "                                                                        Pipeline(steps=[('selector',\n",
       "                                                                                         ColumnSelector(key='concatenated_tags')),\n",
       "                                                                                        ('countvectorizer',\n",
       "                                                                                         CountVectorizer())]))])),\n",
       "                                       ('multinomialnb', MultinomialNB())]),\n",
       "             n_jobs=3,\n",
       "             param_grid={'multinomialnb__alpha': [1e-05, 0.01, 1],\n",
       "                         'union__concatenated_tags__countvectorizer__ngram_range': [(1,\n",
       "                                                                                     5)],\n",
       "                         'union__title__countvectorizer__ngram_range': [(1,\n",
       "                                                                         5)]})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"union__title__countvectorizer__ngram_range\": [(1, 5)],\n",
    "    \"union__concatenated_tags__countvectorizer__ngram_range\": [(1, 5)],\n",
    "    \"multinomialnb__alpha\": [1.0e-5, 1.0e-2, 1]\n",
    "}\n",
    "\n",
    "classifier = GridSearchCV(pipeline, cv=5, param_grid=param_grid, n_jobs=cpu_count() - 1)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723e2af1",
   "metadata": {},
   "source": [
    "### Verificando a performance do classificador obtido\n",
    "\n",
    "O resultado foi bom dentro do possível com o desbalanceamento das classes. As métricas são salvas em um arquivo para possíveis consultas futuras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed9286b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "              Bebê       0.92      0.91      0.91      2108\n",
      "Bijuterias e Jóias       0.92      0.95      0.93       285\n",
      "         Decoração       0.92      0.92      0.92      2654\n",
      "     Lembrancinhas       0.93      0.94      0.93      5328\n",
      "            Outros       0.82      0.81      0.82       344\n",
      "       Papel e Cia       0.80      0.82      0.81       833\n",
      "\n",
      "          accuracy                           0.92     11552\n",
      "         macro avg       0.89      0.89      0.89     11552\n",
      "      weighted avg       0.92      0.92      0.92     11552\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, classifier.predict(X_test))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4819e8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.environ[\"METRICS_PATH\"], \"w\") as metrics_file:\n",
    "    metrics_file.write(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319ccbee",
   "metadata": {},
   "source": [
    "## 3. Exportação do modelo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99377430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudpickle\n",
    "\n",
    "with open(os.environ[\"MODEL_PATH\"], \"wb\") as model_file:\n",
    "    cloudpickle.dump(classifier, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38c2f0ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'multinomialnb__alpha': 0.01,\n",
       " 'union__concatenated_tags__countvectorizer__ngram_range': (1, 5),\n",
       " 'union__title__countvectorizer__ngram_range': (1, 5)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
